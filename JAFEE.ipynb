{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input, Subtract, Lambda\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "  \"surprise\": 0,\n",
    "  \"angry\": 1,\n",
    "  \"happy\": 2,\n",
    "  \"fear\": 3,\n",
    "  \"disgust\": 4,\n",
    "  \"sad\": 5,\n",
    "  \"neutral\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(str1):\n",
    "    for i in range (len(str1)-5,0,-1):\n",
    "        try:\n",
    "            z = int(str1[i])\n",
    "        except:\n",
    "            return str1[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(im,k):\n",
    "    im = plt.imread('../Datasets/Facial-Expression-Recognization-using-JAFFE-master/jaffe/AllFiles/'+im.numpy()[k].decode('utf8'))\n",
    "    im = im.astype('float32')\n",
    "    im = im/255\n",
    "    im=cv2.resize(im,(128,128))\n",
    "    img = im.reshape((-1,128 * 128))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-id10\n",
      "\n",
      "Loaded the images of dataset-id1\n",
      "\n",
      "Loaded the images of dataset-id4\n",
      "\n",
      "Loaded the images of dataset-id8\n",
      "\n",
      "Loaded the images of dataset-id9\n",
      "\n",
      "Loaded the images of dataset-id6\n",
      "\n",
      "Loaded the images of dataset-id7\n",
      "\n",
      "Loaded the images of dataset-id2\n",
      "\n",
      "Loaded the images of dataset-id5\n",
      "\n",
      "Loaded the images of dataset-id3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = '../Datasets/Facial-Expression-Recognization-using-JAFFE-master/id'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "n_class = 7\n",
    "img_data_list=[]\n",
    "x = []\n",
    "y = []\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    combinations = list(itertools.combinations(range(len(img_list)), 2))\n",
    "    for i in range (len(combinations)):\n",
    "        imgName1 = img_list[combinations[i][0]]\n",
    "        imgName2 = img_list[combinations[i][1]]\n",
    "#         label1 = labels[abc(imgName1)]\n",
    "#         label2 = labels[abc(imgName2)]\n",
    "        label1 = tf.one_hot(labels[abc(imgName1)], n_class)\n",
    "        label2 = tf.one_hot(labels[abc(imgName2)], n_class)\n",
    "#         img1 = plt.imread(data_path + '/'+ dataset + '/'+ imgName1)\n",
    "#         img2 = plt.imread(data_path + '/'+ dataset + '/'+ imgName2)\n",
    "#         img1 = cv2.resize(img1,(128,128))\n",
    "#         img2 = cv2.resize(img2,(128,128))\n",
    "#         img1 = img1.astype('float32')\n",
    "#         img1 = img1/255\n",
    "#         img2 = img2.astype('float32')\n",
    "#         img2 = img2/255\n",
    "#         img1 = img1.reshape((-1, 128 * 128))\n",
    "#         img2 = img2.reshape((-1, 128 * 128))\n",
    "        x.append((imgName1,imgName2))\n",
    "        y.append((label1,label2))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# img_data = img_data.reshape((-1, 128 * 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2152"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x[:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y[:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Original_input (InputLayer)     [(None, 16384)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         16778240    Original_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1024)         1049600     dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          524800      dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Latent_variables (Dense)        (None, 500)          256500      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Observed_variables (Dense)      (None, 7)            3591        dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,612,731\n",
      "Trainable params: 18,612,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building model\n",
    "n_class = 7\n",
    "input_dim = 16384\n",
    "z_dim = 500\n",
    "\n",
    "\n",
    "\n",
    "# Encoder\n",
    "def make_encoder_model():\n",
    "    inputs = tf.keras.Input(shape=(input_dim,), name='Original_input')\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    latent = tf.keras.layers.Dense(z_dim, activation='linear', name='Latent_variables')(x)\n",
    "    observed = tf.keras.layers.Dense(n_class, activation='softmax', name='Observed_variables')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[latent, observed], name='Encoder')\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = make_encoder_model()\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decoder\n",
    "def make_decoder_model():\n",
    "    inputted_latent = tf.keras.Input(shape=(z_dim,), name='Latent_variables')\n",
    "    inputted_observed = tf.keras.Input(shape=(n_class,), name='Observed_variables')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inputted_latent, inputted_observed], axis=-1)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    reconstruction = tf.keras.layers.Dense(input_dim, activation='linear', name='Reconstruction')(x)\n",
    "    model = tf.keras.Model(inputs=[inputted_latent, inputted_observed], outputs=reconstruction, name='Decoder')\n",
    "    return model\n",
    "\n",
    "\n",
    "decoder = make_decoder_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multipliers\n",
    "alpha = 1000.0\n",
    "beta = 100.0\n",
    "gamma = 1000.0\n",
    "zeta = 100\n",
    "\n",
    "# Loss functions\n",
    "# Reconstruction cost\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Supervised cost\n",
    "cat_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# Unsupervised cross-covariance cost\n",
    "def xcov_loss_fn(latent, observed,batch_size):\n",
    "    latent_centered = latent - tf.reduce_mean(latent, axis=0, keepdims=True)\n",
    "    observed_centered = observed - tf.reduce_mean(observed, axis=0, keepdims=True)\n",
    "    xcov_loss = 0.5 * tf.reduce_sum(\n",
    "        tf.square(tf.matmul(latent_centered, observed_centered, transpose_a=True)))\n",
    "\n",
    "    return xcov_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "n_epochs = 1\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = train_dataset.batch(batch_size)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "# @tf.function\n",
    "def train_on_batch(batch_x, batch_y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Inference\n",
    "        batch_x_1 = np.zeros((batch_size,128*128))\n",
    "        batch_x_2 = np.zeros((batch_size,128*128))\n",
    "        \n",
    "        batch_y_1 = np.zeros((batch_size,7))\n",
    "        batch_y_2 = np.zeros((batch_size,7))\n",
    "        \n",
    "        for i in range (batch_size):     \n",
    "            batch_x_1[i] = getImage(batch_x[i],0)\n",
    "            batch_x_2[i] = getImage(batch_x[i],1)\n",
    "\n",
    "            batch_y_1[i] = batch_y[i].numpy()[0]\n",
    "            batch_y_2[i] = batch_y[i].numpy()[1]\n",
    "            \n",
    "        batch_latent_1, batch_observed_1 = encoder(batch_x_1)\n",
    "        batch_latent_2, batch_observed_2 = encoder(batch_x_2)\n",
    "        batch_reconstruction_1 = decoder([batch_latent_1, batch_observed_1])\n",
    "        batch_reconstruction_2 = decoder([batch_latent_2, batch_observed_2])\n",
    "        \n",
    "#         plt.figure()\n",
    "#         print(batch_x_1)\n",
    "#         print(batch_observed_1)\n",
    "        # Loss functions\n",
    "        recon_loss_1 = alpha * mse_loss_fn(batch_x_1, batch_reconstruction_1)\n",
    "        recon_loss_2 = alpha * mse_loss_fn(batch_x_2, batch_reconstruction_2)\n",
    "#         print(batch_reconstruction_1.shape)\n",
    "#         plt.imshow(batch_latent_1)\n",
    "#     plt.imshow(batch_latent_1)\n",
    "        \n",
    "        cat_loss_1 = beta * cat_loss_fn(batch_y_1, batch_observed_1)\n",
    "        cat_loss_2 = beta * cat_loss_fn(batch_y_2, batch_observed_2)\n",
    "        \n",
    "        xcov_loss_1 = gamma * xcov_loss_fn(batch_latent_1, batch_observed_1, tf.cast(tf.shape(batch_x_1)[0], tf.float32))\n",
    "        xcov_loss_2 = gamma * xcov_loss_fn(batch_latent_2, batch_observed_2, tf.cast(tf.shape(batch_x_2)[0], tf.float32))\n",
    "    \n",
    "        similarity_loss = zeta*mse_loss_fn(batch_latent_1,batch_latent_2)\n",
    "        \n",
    "        # Final loss function\n",
    "        ae_loss = recon_loss_1 + recon_loss_2 + cat_loss_1 +cat_loss_2 + xcov_loss_1 + xcov_loss_2 + similarity_loss\n",
    "               \n",
    "    gradients = tape.gradient(ae_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, encoder.trainable_variables + decoder.trainable_variables))\n",
    "    recon_loss = (recon_loss_1 + recon_loss_2)/2\n",
    "    cat_loss = (cat_loss_1 + cat_loss_2)/2\n",
    "    xcov_loss = (xcov_loss_1 + xcov_loss_2)/2\n",
    "    return recon_loss, cat_loss, xcov_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Rec1 tf.Tensor(244.77054, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(208.5381, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.02782128, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(316.96625, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(197.6529, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.016560955, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(206.92264, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(663.6678, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.89562964, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(102.310616, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(311.93085, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(9.543593, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(69.80679, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(233.74936, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(2.4825943, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(35.811996, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(377.3517, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.7367378, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(18.89843, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(335.285, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(9.827499, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(38.135002, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(340.83707, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(29.673624, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(27.703407, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(403.69965, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.7135691, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(34.34197, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(184.7691, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(16.46097, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(19.731512, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(157.88431, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(498.40976, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(25.963768, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(713.9901, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.19673777, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(19.512905, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(550.22723, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.00018984184, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(15.215083, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(406.64142, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(11.816527, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(19.189701, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(807.56683, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.03148103, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(21.275175, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(807.0322, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.04604302, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(10.28605, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(543.6684, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.5317336, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(18.194078, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9112, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(82.31205, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(11.377621, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(308.82513, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(5.498838e-09, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(19.292953, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.90485, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(3.3300353e-17, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(11.372404, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(5.417896e-14, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(13.43207, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(1.8178677e-25, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(10.868699, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(402.9524, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(5.2630304e-21, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(12.10095, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(4.1319175e-37, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(12.684937, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(5.1848e-41, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(20.095495, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(8.29569e-40, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(12.332823, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(2.3341004e-31, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.707619, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(402.9524, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(17.330925, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.051527, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(805.9048, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(2.4180402e-33, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(20.213852, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(13.256069, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1208.8572, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(3.840439e-34, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(17.156616, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(15.073648, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.937675, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(8.065842, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(1.1868998e-38, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.930902, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1208.8572, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(9.460968, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.233383, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(7.39325e-39, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(15.588415, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(16.118591, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1208.8572, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(1.9798245e-38, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(17.086594, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(19.36143, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(10.435054, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(15.215522, shape=(), dtype=float32)\n",
      "Rec1 tf.Tensor(1611.8096, shape=(), dtype=float32)\n",
      "Rec2 tf.Tensor(1.315819e-39, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-422183311932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxcov_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mepoch_recon_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_cat_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-0b83bb8a5fe5>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(batch_x, batch_y)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecon_loss_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecon_loss_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mcat_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcat_loss_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcat_loss_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m           update_ops.extend(\n\u001b[1;32m    484\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 485\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    202\u001b[0m           \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;34m\"ResourceApplyAdam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mbeta1_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m         \"use_locking\", use_locking, \"use_nesterov\", use_nesterov)\n\u001b[0m\u001b[1;32m   1526\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Functions to calculate epoch's mean performance\n",
    "    epoch_recon_loss_avg = tf.metrics.Mean()\n",
    "    epoch_cat_loss_avg = tf.metrics.Mean()\n",
    "    epoch_xcov_loss_avg = tf.metrics.Mean()\n",
    "\n",
    "    for batch, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        recon_loss, cat_loss, xcov_loss = train_on_batch(batch_x, batch_y)\n",
    "        epoch_recon_loss_avg(recon_loss)\n",
    "        epoch_cat_loss_avg(cat_loss)\n",
    "        epoch_xcov_loss_avg(xcov_loss)\n",
    "        \n",
    "\n",
    "    epoch_time = time.time() - start\n",
    "    print('{:3d}: {:.2f}s ETA: {:.2f}s  Reconstruction cost: {:.4f}  Supervised cost: {:.4f}  XCov cost: {:.4f}'\n",
    "          .format(epoch + 1, epoch_time,\n",
    "                  epoch_time * (n_epochs - epoch),\n",
    "                  epoch_recon_loss_avg.result(),\n",
    "                  epoch_cat_loss_avg.result(),\n",
    "                epoch_xcov_loss_avg.result()))\n",
    "\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
